profile: "production"

environment:
  model_name: "gemma-3-27b-it"
  description: "Gemma 3 27B Instruct (生产环境部署)"
  template: "gemma3"
  inference_engine: "vllm"

  vllm_config:
    tensor_parallel_size: 1
    gpu_memory_utilization: 0.9
    max_model_len: 16384
    dtype: "auto"

  service_config:
    host: "0.0.0.0"
    port: 8000
    log_level: "info"

  generation_defaults:
    temperature: 0.7
    max_tokens: 1024
    top_p: 0.9
    stream: false

common:
  model_args:
    trust_remote_code: true
    use_fast_tokenizer: false
    low_cpu_mem_usage: true
    flash_attn: "auto"
    cache_dir: null

  required_packages:
    - "fastapi"
    - "uvicorn"
    - "pydantic"
    - "transformers"
    - "torch"

